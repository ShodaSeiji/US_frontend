import streamlit as st
import pandas as pd
import requests

# ãƒšãƒ¼ã‚¸è¨­å®š
st.set_page_config(page_title="ç ”Q - æµ·å¤–ç ”ç©¶è€…ãƒãƒƒãƒãƒ³ã‚°", layout="wide")

# ãƒ­ã‚´ã®è¡¨ç¤º
st.image("logo_kenQ.png", width=250)
st.title("æµ·å¤–ç ”ç©¶è€…ãƒãƒƒãƒãƒ³ã‚° - Harvard Edition")

# Step 1: å›½ã®é¸æŠï¼ˆç¾åœ¨ã¯United Stateså›ºå®šï¼‰
country = st.selectbox("Select Country / å›½ã‚’é¸ã‚“ã§ãã ã•ã„", ["United States"])

# Step 2: æ‰€å±å¤§å­¦ã®é¸æŠ
universities = [
    "All",
    "Harvard University",
    "Harvard Medical School",
    "Harvard Kennedy School",
    "Harvard T.H. Chan School of Public Health",
    "Harvard Business School",
    "Harvard School of Engineering and Applied Sciences",
    "Harvard Divinity School",
    "Harvard Graduate School of Education",
    "Harvard Law School"
]
university = st.selectbox("Select Institution / æ‰€å±ã‚’é¸ã‚“ã§ãã ã•ã„", universities)
selected_university = "" if university == "All" else university.strip()

# Step 3: ç ”ç©¶ãƒˆãƒ”ãƒƒã‚¯ã®å…¥åŠ›
query = st.text_input("Research Topic / ç ”ç©¶ãƒˆãƒ”ãƒƒã‚¯ã‚’å…¥åŠ›", key="research_query")

# âœ… Step 4: è©³ç´°ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ï¼ˆæ–°æ©Ÿèƒ½ï¼‰
with st.expander("ğŸ” è©³ç´°ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰"):
    col1, col2 = st.columns(2)
    
    with col1:
        min_works = st.number_input("æœ€å°è«–æ–‡æ•°", min_value=0, value=0, step=10)
        min_citations = st.number_input("æœ€å°è¢«å¼•ç”¨æ•°", min_value=0, value=0, step=100)
    
    with col2:
        min_h_index = st.number_input("æœ€å°hæŒ‡æ•°", min_value=0, value=0, step=5)
        research_fields = st.multiselect(
            "ç ”ç©¶åˆ†é‡",
            ["Arts_Sciences", "Medical", "Engineering", "Business", "Law", "Education"],
            default=[]
        )

# Step 5: è¡¨ç¤ºä»¶æ•°ã®é¸æŠ
display_limit = st.selectbox("è¡¨ç¤ºä»¶æ•°", [5, 10, 20, 50], index=1)

# Step 6: æ¤œç´¢å‡¦ç†
if st.button("Search", type="primary"):
    if not query.strip():
        st.warning("ç ”ç©¶ãƒˆãƒ”ãƒƒã‚¯ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
    else:
        st.write(f"ğŸ” Searching researchers from **{university}** related to '**{query}**'...")

        # âœ… ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰APIã®URLï¼ˆæœ¬ç•ªç’°å¢ƒã«å¿œã˜ã¦å¤‰æ›´ï¼‰
        api_url = "https://app-kenq-4-hweychffaqhaf8a3.canadacentral-01.azurewebsites.net/api/search"
        # api_url = "http://localhost:3000/api/search"  # ãƒ­ãƒ¼ã‚«ãƒ«ãƒ†ã‚¹ãƒˆç”¨
        # api_url = "https://app-kenq-4-hweychffaqhaf8a3.canadacentral-01.azurewebsites.net/api/search" #æœ¬ç•ªç”¨
        payload = {
            "country": country,
            "university": selected_university,
            "query": query
        }

        try:
            with st.spinner('æ¤œç´¢ä¸­...'):
                response = requests.post(api_url, json=payload, timeout=30)
                response.raise_for_status()
                results = response.json()

            # çµæœè¡¨ç¤º
            if results:
                # âœ… ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ï¼ˆãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰å´ï¼‰
                filtered_results = []
                for item in results:
                    # è«–æ–‡æ•°ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼
                    if min_works > 0 and item.get('works_count', 0) < min_works:
                        continue
                    # è¢«å¼•ç”¨æ•°ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼
                    if min_citations > 0 and item.get('cited_by_count', 0) < min_citations:
                        continue
                    # hæŒ‡æ•°ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼
                    if min_h_index > 0 and item.get('h_index', 0) < min_h_index:
                        continue
                    # ç ”ç©¶åˆ†é‡ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼
                    if research_fields and item.get('classified_field', '') not in research_fields:
                        continue
                    
                    filtered_results.append(item)

                # è¡¨ç¤ºä»¶æ•°åˆ¶é™
                display_results = filtered_results[:display_limit]
                
                if display_results:
                    st.success(f"ğŸ”æ¤œç´¢çµæœï¼ˆ{len(display_results)}ä»¶ / å…¨{len(results)}ä»¶ä¸­ï¼‰ã‚’è¡¨ç¤ºã—ã¾ã™ã€‚")
                    
                    # âœ… çµ±è¨ˆæƒ…å ±ã®è¡¨ç¤º
                    if len(results) > 1:
                        avg_works = sum(item.get('works_count', 0) for item in results) / len(results)
                        avg_citations = sum(item.get('cited_by_count', 0) for item in results) / len(results)
                        avg_h_index = sum(item.get('h_index', 0) for item in results) / len(results)
                        
                        with st.expander("ğŸ“Š æ¤œç´¢çµæœçµ±è¨ˆ"):
                            col1, col2, col3 = st.columns(3)
                            col1.metric("å¹³å‡è«–æ–‡æ•°", f"{avg_works:.0f}ä»¶")
                            col2.metric("å¹³å‡è¢«å¼•ç”¨æ•°", f"{avg_citations:.0f}å›")
                            col3.metric("å¹³å‡hæŒ‡æ•°", f"{avg_h_index:.1f}")

                    # ç ”ç©¶è€…æƒ…å ±ã®è¡¨ç¤º
                    for i, item in enumerate(display_results, 1):
                        st.markdown("---")
                        
                        # âœ… ç ”ç©¶è€…åŸºæœ¬æƒ…å ±ï¼ˆå¼·åŒ–ç‰ˆï¼‰
                        col1, col2 = st.columns([2, 1])
                        
                        with col1:
                            st.markdown(f"### ğŸ‘¨â€ğŸ”¬ {item.get('name', 'No Name')}")
                            st.markdown(f"**Institution / æ‰€å±:** {item.get('institution', 'N/A')}")
                            st.markdown(f"**Research Field / ç ”ç©¶åˆ†é‡:** {item.get('classified_field', 'N/A')}")

                            orcid_url = item.get("orcid", "").strip()
                            if orcid_url and orcid_url != "N/A":
                                if not orcid_url.startswith("http"):
                                    orcid_url = f"https://orcid.org/{orcid_url}"
                                st.markdown(f"**ORCID:** [{orcid_url}]({orcid_url})")
                            else:
                                st.markdown("**ORCID:** N/A")
                        
                        with col2:
                            # âœ… ç ”ç©¶å®Ÿç¸¾ãƒ¡ãƒˆãƒªã‚¯ã‚¹
                            st.markdown("**ğŸ“ˆ Research Metrics**")
                            
                            # works_countã¨paper_countã®ä¸¡æ–¹ã«å¯¾å¿œ
                            works_count = item.get('works_count', item.get('paper_count', 0))
                            st.metric("è«–æ–‡æ•°", f"{works_count:,}ä»¶")
                            st.metric("è¢«å¼•ç”¨æ•°", f"{item.get('cited_by_count', 0):,}å›")
                            st.metric("hæŒ‡æ•°", item.get('h_index', 0))
                            
                            # CSVãƒ‡ãƒ¼ã‚¿ã§ã®è«–æ–‡ä»¶æ•°ã‚‚è¡¨ç¤º
                            if item.get('paper_data_count'):
                                st.caption(f"ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹åéŒ²è«–æ–‡: {item.get('paper_data_count')}ä»¶")

                        # âœ… ãŠã™ã™ã‚ç†ç”±ã®è¡¨ç¤ºï¼ˆå¼·åŒ–ç‰ˆï¼‰
                        with st.expander("ğŸ’¡ ãŠã™ã™ã‚ã™ã‚‹ç†ç”±ã‚’è¦‹ã‚‹", expanded=False):
                            reasons_displayed = False
                            for j in range(1, 4):
                                title = item.get(f"reason_title_{j}", "").strip()
                                body = item.get(f"reason_body_{j}", "").strip()
                                if title or body:
                                    if title:
                                        st.markdown(f"**ğŸ¯ ç†ç”±{j}: {title}**")
                                    if body:
                                        st.write(body)
                                    if j < 3:  # æœ€å¾Œä»¥å¤–ã¯åŒºåˆ‡ã‚Šç·š
                                        st.markdown("---")
                                    reasons_displayed = True
                            if not reasons_displayed:
                                st.write("ç†ç”±ã¯è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
                
                else:
                    st.warning("ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼æ¡ä»¶ã«ä¸€è‡´ã™ã‚‹ç ”ç©¶è€…ã¯è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚æ¡ä»¶ã‚’ç·©ã‚ã¦å†æ¤œç´¢ã—ã¦ãã ã•ã„ã€‚")
                    
                    # ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼å‰ã®ä»¶æ•°ã‚’è¡¨ç¤º
                    if len(results) > 0:
                        st.info(f"ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼é©ç”¨å‰ã¯{len(results)}ä»¶ã®çµæœãŒã‚ã‚Šã¾ã—ãŸã€‚")
                        
            else:
                st.warning("è©²å½“ã™ã‚‹ç ”ç©¶è€…ã¯è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")

        except requests.exceptions.Timeout:
            st.error("â° æ¤œç´¢ãŒã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã—ã¾ã—ãŸã€‚ã—ã°ã‚‰ãå¾…ã£ã¦ã‹ã‚‰å†åº¦ãŠè©¦ã—ãã ã•ã„ã€‚")
        except requests.exceptions.RequestException as e:
            st.error(f"âŒ APIãƒªã‚¯ã‚¨ã‚¹ãƒˆã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
            if "localhost" in api_url:
                st.info("ğŸ’¡ ãƒ­ãƒ¼ã‚«ãƒ«ã‚µãƒ¼ãƒãƒ¼ãŒèµ·å‹•ã—ã¦ã„ã‚‹ã‹ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        except Exception as e:
            st.error(f"âŒ äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")

# âœ… ã‚µã‚¤ãƒ‰ãƒãƒ¼ã«æƒ…å ±ã‚’è¿½åŠ 
with st.sidebar:
    st.markdown("## ğŸ“Š ã‚·ã‚¹ãƒ†ãƒ æƒ…å ±")
    st.markdown("- **ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹**: Harvardç ”ç©¶è€…ãƒ‡ãƒ¼ã‚¿")
    st.markdown("- **ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹**: harvard-index-v6")
    st.markdown("- **æ¤œç´¢ã‚¨ãƒ³ã‚¸ãƒ³**: Azure AI Search")
    st.markdown("- **AI**: Azure OpenAI")
    
    st.markdown("## ğŸ” æ¤œç´¢ã®ã‚³ãƒ„")
    st.markdown("- è‹±èªãƒ»æ—¥æœ¬èªã©ã¡ã‚‰ã§ã‚‚æ¤œç´¢å¯èƒ½")
    st.markdown("- å…·ä½“çš„ãªã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’ä½¿ç”¨")
    st.markdown("- è©³ç´°ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã§çµã‚Šè¾¼ã¿å¯èƒ½")
    
    st.markdown("## ğŸ“ˆ è¡¨ç¤ºã•ã‚Œã‚‹æŒ‡æ¨™")
    st.markdown("- **è«–æ–‡æ•°**: ç ”ç©¶è€…ã®ç·è«–æ–‡æ•°")
    st.markdown("- **è¢«å¼•ç”¨æ•°**: è«–æ–‡ã®è¢«å¼•ç”¨å›æ•°")
    st.markdown("- **hæŒ‡æ•°**: ç ”ç©¶å½±éŸ¿åŠ›ã®æŒ‡æ¨™")